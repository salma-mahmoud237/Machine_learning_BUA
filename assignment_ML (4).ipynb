{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TKrumB_3NKg",
        "outputId": "63271054-6e25-439e-a88d-601e8f87d71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Evaluate Models\n",
            "\n",
            " Model Performance Comparison:\n",
            "| Model                    | Train Accuracy | Test Accuracy |\n",
            "| Decision Tree            | 1.0000       | 0.9474        |\n",
            "| Random Forest            | 1.0000       | 0.9649        |\n",
            "| Gradient Boosting        | 1.0000       | 0.9561        |\n",
            "\n",
            " Top 5 Feature Importances\n",
            "\n",
            " Top 5 features for [Random Forest]:\n",
            "- worst area               : 0.1539\n",
            "- worst concave points     : 0.1447\n",
            "- mean concave points      : 0.1062\n",
            "- worst radius             : 0.0780\n",
            "- mean concavity           : 0.0680\n",
            "\n",
            " Top 5 features for [Gradient Boosting]:\n",
            "- mean concave points      : 0.4505\n",
            "- worst concave points     : 0.2401\n",
            "- worst radius             : 0.0756\n",
            "- worst perimeter          : 0.0514\n",
            "- worst texture            : 0.0399\n",
            "\n",
            " Final Comparison and Conclusion\n",
            " The model with the best test accuracy is: [Random Forest] (0.9649)\n"
          ]
        }
      ],
      "source": [
        "#sheet4 Q4:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "feature_names = cancer.feature_names\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "print(\"Train and Evaluate Models\")\n",
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "dt_model.fit(X_train, y_train)\n",
        "results['Decision Tree'] = {\n",
        "    'Train Acc': dt_model.score(X_train, y_train),\n",
        "    'Test Acc': dt_model.score(X_test, y_test)\n",
        "}\n",
        "\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
        "rf_model.fit(X_train, y_train)\n",
        "results['Random Forest'] = {\n",
        "    'Train Acc': rf_model.score(X_train, y_train),\n",
        "    'Test Acc': rf_model.score(X_test, y_test)\n",
        "}\n",
        "\n",
        "\n",
        "gb_model = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
        "gb_model.fit(X_train, y_train)\n",
        "results['Gradient Boosting'] = {\n",
        "    'Train Acc': gb_model.score(X_train, y_train),\n",
        "    'Test Acc': gb_model.score(X_test, y_test)\n",
        "}\n",
        "\n",
        "\n",
        "print(\"\\n Model Performance Comparison:\")\n",
        "print(\"| Model                    | Train Accuracy | Test Accuracy |\")\n",
        "for model_name, accs in results.items():\n",
        "    print(f\"| {model_name.ljust(24)} | {accs['Train Acc']:.4f}       | {accs['Test Acc']:.4f}        |\")\n",
        "\n",
        "print(\"\\n Top 5 Feature Importances\")\n",
        "\n",
        "\n",
        "importances_rf = rf_model.feature_importances_\n",
        "feature_importance_rf = sorted(zip(feature_names, importances_rf), key=itemgetter(1), reverse=True)\n",
        "\n",
        "print(\"\\n Top 5 features for [Random Forest]:\")\n",
        "for name, importance in feature_importance_rf[:5]:\n",
        "    print(f\"- {name.ljust(25)}: {importance:.4f}\")\n",
        "\n",
        "importances_gb = gb_model.feature_importances_\n",
        "feature_importance_gb = sorted(zip(feature_names, importances_gb), key=itemgetter(1), reverse=True)\n",
        "\n",
        "print(\"\\n Top 5 features for [Gradient Boosting]:\")\n",
        "for name, importance in feature_importance_gb[:5]:\n",
        "    print(f\"- {name.ljust(25)}: {importance:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n Final Comparison and Conclusion\")\n",
        "\n",
        "\n",
        "best_test_acc = max(results[m]['Test Acc'] for m in results)\n",
        "best_model = [m for m, accs in results.items() if accs['Test Acc'] == best_test_acc][0]\n",
        "\n",
        "print(f\" The model with the best test accuracy is: [{best_model}] ({best_test_acc:.4f})\")\n",
        "\n",
        "top5_rf_names = [name for name, _ in feature_importance_rf[:5]]\n",
        "top5_gb_names = [name for name, _ in feature_importance_gb[:5]]\n",
        "intersection = set(top5_rf_names).intersection(top5_gb_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assignment sheet4:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from operator import itemgetter\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "feature_names = cancer.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        ")\n",
        "results = {}\n",
        "\n",
        "print(\"Decision Tree (Full and Pruned) & Overfitting Comparison\")\n",
        "\n",
        "dt_full = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "dt_full.fit(X_train, y_train)\n",
        "results['Decision Tree (Full)'] = {\n",
        "    'Train Acc': dt_full.score(X_train, y_train),\n",
        "    'Test Acc': dt_full.score(X_test, y_test)\n",
        "}\n",
        "\n",
        "dt_pruned = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)\n",
        "dt_pruned.fit(X_train, y_train)\n",
        "results['Decision Tree (Pruned)'] = {\n",
        "    'Train Acc': dt_pruned.score(X_train, y_train),\n",
        "    'Test Acc': dt_pruned.score(X_test, y_test)\n",
        "}\n",
        "\n",
        "print(\"| Model                    | Train Accuracy | Test Accuracy |\")\n",
        "print(f\"| {'Decision Tree (Full)'.ljust(24)} | {results['Decision Tree (Full)']['Train Acc']:.4f}       | {results['Decision Tree (Full)']['Test Acc']:.4f}        |\")\n",
        "print(f\"| {'Decision Tree (Pruned)'.ljust(24)} | {results['Decision Tree (Pruned)']['Train Acc']:.4f}       | {results['Decision Tree (Pruned)']['Test Acc']:.4f}        |\")\n",
        "\n",
        "print(\"Overfitting Comment:\")\n",
        "print(f\" DT (Full): High overfitting (Train Acc: {results['Decision Tree (Full)']['Train Acc']:.4f} vs. Test Acc: {results['Decision Tree (Full)']['Test Acc']:.4f})\")\n",
        "print(f\" DT (Pruned): Reduced overfitting, better generalization (Train Acc: {results['Decision Tree (Pruned)']['Train Acc']:.4f} vs. Test Acc: {results['Decision Tree (Pruned)']['Test Acc']:.4f})\")\n",
        "\n",
        "print(\"Train Random Forest and Compare with Decision Trees\")\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
        "rf_model.fit(X_train, y_train)\n",
        "results['Random Forest (100)'] = {\n",
        "    'Train Acc': rf_model.score(X_train, y_train),\n",
        "    'Test Acc': rf_model.score(X_test, y_test)\n",
        "}\n",
        "\n",
        "print(\"| Model                    | Train Accuracy | Test Accuracy |\")\n",
        "print(f\"| {'Random Forest (100)'.ljust(24)} | {results['Random Forest (100)']['Train Acc']:.4f}       | {results['Random Forest (100)']['Test Acc']:.4f}        |\")\n",
        "print(f\"| {'Decision Tree (Pruned)'.ljust(24)} | {results['Decision Tree (Pruned)']['Train Acc']:.4f}       | {results['Decision Tree (Pruned)']['Test Acc']:.4f}        |\")\n",
        "print(\"Comparison:\")\n",
        "\n",
        "learning_rates = [0.01, 0.1]\n",
        "n_estimators_list = [50, 100, 200]\n",
        "gb_tuning_results = []\n",
        "\n",
        "print(\"| Learning Rate | N_Estimators | Train Accuracy | Test Accuracy |\")\n",
        "\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for n_est in n_estimators_list:\n",
        "        gb_model = GradientBoostingClassifier(n_estimators=n_est, learning_rate=lr, random_state=RANDOM_STATE)\n",
        "        gb_model.fit(X_train, y_train)\n",
        "\n",
        "        train_acc = gb_model.score(X_train, y_train)\n",
        "        test_acc = gb_model.score(X_test, y_test)\n",
        "\n",
        "        gb_tuning_results.append({\n",
        "            'lr': lr,\n",
        "            'n_est': n_est,\n",
        "            'Train Acc': train_acc,\n",
        "            'Test Acc': test_acc\n",
        "        })\n",
        "\n",
        "        print(f\"| {lr:.2f}          | {n_est:<12} | {train_acc:.4f}         | {test_acc:.4f}        |\")\n",
        "\n",
        "gb_final = GradientBoostingClassifier(random_state=RANDOM_STATE).fit(X_train, y_train)\n",
        "rf_final = rf_model\n",
        "\n",
        "print(\"Top 5 Feature Importances\")\n",
        "\n",
        "importances_rf = rf_final.feature_importances_\n",
        "feature_importance_rf = sorted(zip(feature_names, importances_rf), key=itemgetter(1), reverse=True)\n",
        "\n",
        "print(\"\\n Top 5 features for Random Forest:\")\n",
        "for name, importance in feature_importance_rf[:5]:\n",
        "    print(f\"- {name.ljust(25)}: {importance:.4f}\")\n",
        "\n",
        "importances_gb = gb_final.feature_importances_\n",
        "feature_importance_gb = sorted(zip(feature_names, importances_gb), key=itemgetter(1), reverse=True)\n",
        "\n",
        "print(\"\\n Top 5 features for Gradient Boosting (Default):\")\n",
        "for name, importance in feature_importance_gb[:5]:\n",
        "    print(f\"- {name.ljust(25)}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS7WkImdSSwp",
        "outputId": "28d710ea-7e56-47af-ec35-1b61b2ab4c11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree (Full and Pruned) & Overfitting Comparison\n",
            "| Model                    | Train Accuracy | Test Accuracy |\n",
            "| Decision Tree (Full)     | 1.0000       | 0.9474        |\n",
            "| Decision Tree (Pruned)   | 0.9780       | 0.9474        |\n",
            "Overfitting Comment:\n",
            " DT (Full): High overfitting (Train Acc: 1.0000 vs. Test Acc: 0.9474)\n",
            " DT (Pruned): Reduced overfitting, better generalization (Train Acc: 0.9780 vs. Test Acc: 0.9474)\n",
            "Train Random Forest and Compare with Decision Trees\n",
            "| Model                    | Train Accuracy | Test Accuracy |\n",
            "| Random Forest (100)      | 1.0000       | 0.9649        |\n",
            "| Decision Tree (Pruned)   | 0.9780       | 0.9474        |\n",
            "Comparison:\n",
            "| Learning Rate | N_Estimators | Train Accuracy | Test Accuracy |\n",
            "| 0.01          | 50           | 0.9780         | 0.9561        |\n",
            "| 0.01          | 100          | 0.9868         | 0.9561        |\n",
            "| 0.01          | 200          | 0.9934         | 0.9561        |\n",
            "| 0.10          | 50           | 1.0000         | 0.9561        |\n",
            "| 0.10          | 100          | 1.0000         | 0.9561        |\n",
            "| 0.10          | 200          | 1.0000         | 0.9561        |\n",
            "Top 5 Feature Importances\n",
            "\n",
            " Top 5 features for Random Forest:\n",
            "- worst area               : 0.1539\n",
            "- worst concave points     : 0.1447\n",
            "- mean concave points      : 0.1062\n",
            "- worst radius             : 0.0780\n",
            "- mean concavity           : 0.0680\n",
            "\n",
            " Top 5 features for Gradient Boosting (Default):\n",
            "- mean concave points      : 0.4505\n",
            "- worst concave points     : 0.2401\n",
            "- worst radius             : 0.0756\n",
            "- worst perimeter          : 0.0514\n",
            "- worst texture            : 0.0399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assignment sheet3 Q1:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "cancer = load_breast_cancer(as_frame=True)\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logistic_regression', LogisticRegression(random_state=42, solver='liblinear'))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Model Performance Evaluation\")\n",
        "print(f\"* Accuracy: {accuracy:.4f}\")\n",
        "print(f\"* Precision: {precision:.4f}\")\n",
        "print(f\"* Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"* F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsN5AH0FZGV5",
        "outputId": "bf9f12ab-0313-4875-c39e-14f996def1ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Evaluation\n",
            "* Accuracy: 0.9737\n",
            "* Precision: 0.9722\n",
            "* Recall (Sensitivity): 0.9859\n",
            "* F1-Score: 0.9790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assignment sheet3 Q2:\n",
        "\n",
        "coefficients = pipeline['logistic_regression'].coef_[0]\n",
        "feature_names = X.columns\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients\n",
        "})\n",
        "\n",
        "\n",
        "feature_importance['Absolute_Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
        "feature_importance = feature_importance.sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "\n",
        "print(feature_importance[['Feature', 'Coefficient']].head(10).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpkBVcb8aK3S",
        "outputId": "7a9fe763-f61c-4f4c-e9d6-438edbe79448"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Feature  Coefficient\n",
            "       worst texture    -1.335651\n",
            "        radius error    -1.283117\n",
            "      worst symmetry    -1.196087\n",
            " mean concave points    -1.130510\n",
            "          area error    -0.944861\n",
            "     worst concavity    -0.942150\n",
            "          worst area    -0.882949\n",
            "        worst radius    -0.881042\n",
            "      mean concavity    -0.818323\n",
            "worst concave points    -0.766904\n"
          ]
        }
      ]
    }
  ]
}